prometheus.scrape "spring_boot" {
    targets = [
        {
            "__address__" = "localhost:9090",
            "__metrics_path__" = "/server/actuator/prometheus",
            "job" = "spring-boot",
            "instance" = sys.env("SERVER_NAME"),
            "environment" = sys.env("ALLOY_ENV"),
            "server_type" = "application",
        },
    ]
    scrape_interval = "15s"
    scrape_timeout = "10s"
    forward_to = [prometheus.remote_write.central.receiver]
}

prometheus.exporter.unix "system" {
    filesystem {
        mount_points_exclude = "^/(sys|proc|dev|host|etc)($|/)"
        fs_types_exclude = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
    }
    enable_collectors = ["processes"]
}

prometheus.scrape "system" {
    targets = prometheus.exporter.unix.system.targets
    job_name = "node"
    scrape_interval = "15s"
    scrape_timeout = "10s"

    forward_to = [prometheus.relabel.system_labels.receiver]
}

prometheus.relabel "system_labels" {
    forward_to = [prometheus.remote_write.central.receiver]

    rule {
        target_label = "instance"
        replacement = sys.env("SERVER_NAME")
    }

    rule {
        target_label = "environment"
        replacement = sys.env("ALLOY_ENV")
    }

    rule {
        target_label = "server_type"
        replacement = "system"
    }
}

// ========== MySQL Exporter (DB 내부 지표) ==========
prometheus.exporter.mysql "rds_mysql" {
  data_source_name = sys.env("DB_USER") + ":" + sys.env("DB_PASSWORD") + "@tcp(ddingdong-dev.c8bj0rlp6aer.ap-northeast-2.rds.amazonaws.com:3306)/"
}

// ========== CloudWatch Exporter (RDS 리소스 지표) ==========
prometheus.exporter.cloudwatch "rds_cw" {
  sts_region = "ap-northeast-2"

  static "rds"{
    namespace = "AWS/RDS"
    regions = ["ap-northeast-2"]

    dimensions = {
        DBInstanceIdentifier = "ddingdong-dev",
    }

    metric {
      name       = "CPUUtilization"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "FreeableMemory"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "FreeStorageSpace"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "DatabaseConnections"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "ReadIOPS"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "WriteIOPS"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "ReadLatency"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "WriteLatency"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "ReplicaLag"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    // ===== 추가된 Throughput 메트릭 =====
    metric {
      name       = "ReadThroughput"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }

    metric {
      name       = "WriteThroughput"
      statistics = ["Average"]
      period     = "30s"
      length     = "5m"
    }
  }
}

prometheus.scrape "mysql_scrape" {
  targets = prometheus.exporter.mysql.rds_mysql.targets
  scrape_interval = "30s"
  scrape_timeout = "10s"
  forward_to = [prometheus.remote_write.central.receiver]
}

// CloudWatch 스크래핑
prometheus.scrape "cloudwatch_scrape" {
  targets = prometheus.exporter.cloudwatch.rds_cw.targets
  scrape_interval = "60s"
  scrape_timeout = "30s"
  forward_to = [prometheus.remote_write.central.receiver]
}

prometheus.remote_write "central" {
    endpoint {
        url = "http://3.39.151.102:9090/api/v1/write"
        remote_timeout = "30s"
        queue_config {
            capacity = 10000
            max_shards = 10
            min_shards = 1
            max_samples_per_send = 1000
            batch_send_deadline = "5s"
        }
    }
    wal {
        truncate_frequency = "2h"
        min_keepalive_time = "5m"
        max_keepalive_time = "8h"
    }
}

otelcol.receiver.otlp "default" {
  http {
    endpoint = "0.0.0.0:4318"
  }
  output {
    traces = [otelcol.exporter.otlphttp.tempo.input]
  }
}

otelcol.exporter.otlphttp "tempo" {
  client {
    endpoint = "http://3.39.151.102:4318/tempo/otlp"
    tls {
      insecure = true
    }
  }
}
